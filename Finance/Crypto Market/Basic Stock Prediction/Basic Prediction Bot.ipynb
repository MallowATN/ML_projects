{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipynb.fs.full.CMC_Webscraping_Final import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    df.columns = ['Date', 'Open','High','Low','Close','Volume','Market Cap']\n",
    "for i in df.columns[1:7]:\n",
    "    df[i] = df[i].str.replace(',','')\n",
    "    df[i] = df[i].str.replace('$','', regex=True)\n",
    "    df[i] = df[i].astype(float)\n",
    "df['Volume'] = df['Volume'].astype(np.int64)\n",
    "df['Market Cap'] = df['Market Cap'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMA(df):\n",
    "    df['SMA_21days'] = df.iloc[:,4].rolling(window=21).mean()\n",
    "    df['SMA_50days'] = df.iloc[:,4].rolling(window=50).mean()\n",
    "    df['SMA_100days'] = df.iloc[:,4].rolling(window=100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(df):\n",
    "    df['EMA_21days'] = df['Close'].ewm(span=21,adjust=False).mean()\n",
    "    df['EMA_50days'] = df['Close'].ewm(span=50,adjust=False).mean()\n",
    "    df['EMA_100days'] = df['Close'].ewm(span=100,adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSIs(df):\n",
    "    df['diff'] = df.Close.diff()\n",
    "    df['pos'] = df['diff'].clip(lower=0)\n",
    "    df['neg'] = -1*df['diff'].clip(upper=0)\n",
    "    ema_pos = df['pos'].ewm(com=13, adjust=False).mean()\n",
    "    ema_neg = df['neg'].ewm(com=13, adjust=False).mean()\n",
    "    relative_str = ema_pos / ema_neg\n",
    "    df['RSI'] = 100-(100/(1+relative_str))\n",
    "    df['Stochastic_RSI'] = (df['RSI']-df['RSI'].rolling(14).min())/(df['RSI'].rolling(14).max()-(df['RSI'].rolling(14).min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMA(df)\n",
    "EMA(df)\n",
    "RSIs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1=df1.drop(['pos','neg','Log Return','diff','Open','High','Low'], axis=1)\n",
    "df1=df1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "# Time series Models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Error Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "\n",
    "\n",
    "#Plotting \n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()['Close'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc['2021-02-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Close',axis=1)\n",
    "Y =(df1['Close'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df1.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True, annot=True, cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "scatter_matrix(df1, figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(k=5, score_func=f_regression)\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "featureScores.nlargest(20,'Score').set_index('Specs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.3\n",
    "train_size = int(len(X) * (1-validation_size))\n",
    "X_train, X_validation = X[0:train_size], X[train_size:len(X)]\n",
    "Y_train, Y_validation = Y[0:train_size], Y[train_size:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring='neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "# models.append(('LR', LinearRegression()))\n",
    "# models.append(('LASSO', Lasso()))\n",
    "# models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "# models.append(('CART', DecisionTreeRegressor()))\n",
    "# models.append(('SVR', SVR()))\n",
    "\n",
    "# models.append(('MLP', MLPRegressor())) #Don't do this lmao, significant error\n",
    "\n",
    "# Boosting methods\n",
    "models.append(('ABR', AdaBoostRegressor()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    "# Bagging methods\n",
    "models.append(('RFR', RandomForestRegressor()))\n",
    "# models.append(('ETR', ExtraTreesRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "kfold_results = []\n",
    "test_results = []\n",
    "train_results = []\n",
    "for name, model in models:\n",
    "    names.append(name)\n",
    "    ## K Fold analysis:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    #converted mean square error to positive. The lower the beter\n",
    "    cv_results = -1* cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    kfold_results.append(cv_results)\n",
    "    \n",
    "    # Full Training period\n",
    "    res = model.fit(X_train, Y_train)\n",
    "    train_result = mean_squared_error(res.predict(X_train), Y_train)\n",
    "    train_results.append(train_result)\n",
    "    # Test results\n",
    "    test_result = mean_squared_error(res.predict(X_validation), Y_validation)\n",
    "    test_results.append(test_result)\n",
    "    msg = \"%s: %f (%f) %f %f\" % (name, cv_results.mean(), cv_results.std(), train_result, test_result)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Kfold analysis between various algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(kfold_results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "ind = np.arange(len(names))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(ind - width/2, train_results,  width=width, label='Train Error')\n",
    "plt.bar(ind + width/2, test_results, width=width, label='Test Error')\n",
    "fig.set_size_inches(15,8)\n",
    "plt.legend()\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "ind = np.arange(len(names))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "fig.suptitle('Comparing the performance of various algorthims on the Train and Test Dataset')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(ind - width/2, train_results,  width=width, label='Train Error')\n",
    "plt.bar(ind + width/2, test_results, width=width, label='Test Error')\n",
    "fig.set_size_inches(15,8)\n",
    "plt.legend()\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(names)\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation, predictions))\n",
    "print(r2_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.columns = ['Prediction']\n",
    "y_val = []\n",
    "for i in Y_validation:\n",
    "    y_val.append(i)\n",
    "df2['Y_validation'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "df2[['Prediction','Y_validation']].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pd.Series(predictions.reshape(len(predictions),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mean_squared_error(Y_validation, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d32eb1b7bf085d3f714eac7b15ed9dd5905ff797248614ad9011249d1f526433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
