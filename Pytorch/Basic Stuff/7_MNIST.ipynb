{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8f7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop (batch training)\n",
    "# Model evaluation\n",
    "# GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a85a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision #datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f125f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3664719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080 Ti'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193bf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_size = 784 #28 x 28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacb7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                           transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train = False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30a3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8752d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  100 samples, 1 color channel, 28 pixels by 28 pixels\n",
    "# Labels is only tensor size of 100, for each class labels, we have 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b398de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eac3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_szie, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "#         Be careful, we don't want to apply the softmax here bc we will use cross entropy loss and it\n",
    "#         will apply the softmax for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc96b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c4ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step100/600, loss = 0.4898\n",
      "epoch 1 / 2, step200/600, loss = 0.4184\n",
      "epoch 1 / 2, step300/600, loss = 0.2863\n",
      "epoch 1 / 2, step400/600, loss = 0.2072\n",
      "epoch 1 / 2, step500/600, loss = 0.1688\n",
      "epoch 1 / 2, step600/600, loss = 0.2065\n",
      "epoch 2 / 2, step100/600, loss = 0.2529\n",
      "epoch 2 / 2, step200/600, loss = 0.2090\n",
      "epoch 2 / 2, step300/600, loss = 0.1727\n",
      "epoch 2 / 2, step400/600, loss = 0.2185\n",
      "epoch 2 / 2, step500/600, loss = 0.1794\n",
      "epoch 2 / 2, step600/600, loss = 0.2200\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader): #enumerate func will give us the actual index and data\n",
    "        # 100, 1, 28, 28... we need to reshape\n",
    "        # 100, 784... this is the original shape\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() #zero out gradient to prevent accumulation\n",
    "        loss.backward() #backward\n",
    "        optimizer.step() #update parameter step\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1} / {num_epochs}, step: {i+1}/{n_total_steps}, loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15214326",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0] #give us the the number of samples in the current batch, = 100\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    acc = 100*n_correct / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802d9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 95.6\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
